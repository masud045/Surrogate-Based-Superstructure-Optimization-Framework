{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db178ea0-d23e-483e-8dce-e65146030a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "# Required Libraries\n",
    "from pyomo.environ import *\n",
    "from pyomo.opt import SolverFactory\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f126286-3e5e-4455-91af-50448512eb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Load Pre-trained Keras Models\n",
    "SMR_fh2_model = tf.keras.models.load_model('SMR_fh2.keras')\n",
    "WE_H2_model = tf.keras.models.load_model('WE_ACM_H2_T_N.keras')\n",
    "\n",
    "fn2_fair_model = tf.keras.models.load_model('fn2_fair_plpc.keras')\n",
    "Fn2_P_model = tf.keras.models.load_model('Fn2_P_Fair.keras')\n",
    "\n",
    "Haber_f_model = tf.keras.models.load_model('Haber_f.keras')\n",
    "my_model7 = tf.keras.models.load_model('my_model7.h5')\n",
    "\n",
    "dist_column_f_model = tf.keras.models.load_model('dist_column_f_ffeed_fh2o.keras')\n",
    "dist_column_x_model = tf.keras.models.load_model('dist_column_xnh3_ffeed_fh2o.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31deecf-e4ae-4c52-9b10-df137108dd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Load Pre-trained Keras Models for CAPEX\n",
    "EA_SMR_Model = tf.keras.models.load_model('EA_SMR_Old.keras')\n",
    "\n",
    "EA_CAS_Model = tf.keras.models.load_model('EA_CAS_Old.keras')\n",
    "EA_MAS_Model = tf.keras.models.load_model('EA_MAS_Old.keras')\n",
    "\n",
    "EA_HB_Model = tf.keras.models.load_model('EA_HB_Old.keras')\n",
    "\n",
    "EA_Dist_Model = tf.keras.models.load_model('EA_Dist_Old.keras')\n",
    "\n",
    "# Load Pre-trained Keras Models for OPEX\n",
    "SMR_ne_model = tf.keras.models.load_model('SMR_ne_cal_s.keras')\n",
    "WE_NE_model = tf.keras.models.load_model('WE_ACM_NE_T_N.keras')\n",
    "\n",
    "CASU_ne_model = tf.keras.models.load_model('CASU_ne_W.keras')\n",
    "MASU_ne_model = tf.keras.models.load_model('MASU_ne_kW.keras')\n",
    "\n",
    "HB_ne_model = tf.keras.models.load_model('HB_ne_cal_s.keras')\n",
    "\n",
    "dist_ne_model = tf.keras.models.load_model('dist_column_ne_ffeed_fh2o.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b57f24-628e-4b90-ba2a-17c644ee4ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pyomo.core:Implicitly replacing the Component attribute FH2O_dist (type=<class 'pyomo.core.base.var.ScalarVar'>) on block unknown with a new Component (type=<class 'pyomo.core.base.var.AbstractScalarVar'>).\n",
      "This is usually indicative of a modelling error.\n",
      "To avoid this warning, use block.del_component() and block.add_component().\n"
     ]
    }
   ],
   "source": [
    "# Optimization Model (Pyomo)\n",
    "model = ConcreteModel()\n",
    "\n",
    "# Binary decision variables for each route (0 = not selected, 1 = selected)\n",
    "model.SMR = Var(domain=Binary)\n",
    "model.WE = Var(domain=Binary)\n",
    "model.CAS = Var(domain=Binary)\n",
    "model.MAS = Var(domain=Binary)\n",
    "model.HB = Var(domain=Binary)\n",
    "model.MW = Var(domain=Binary)\n",
    "model.Dist = Var(domain=Binary)\n",
    "model.Mem = Var(domain=Binary)\n",
    "\n",
    "# Continuous decision variables\n",
    "model.FNG = Var(bounds=(80, 120))  # For SMR\n",
    "model.FH2O = Var(bounds=(255, 375))  # For SMR\n",
    "model.Tsr = Var(bounds=(900, 1100))  # For SMR\n",
    "model.Psr = Var(bounds=(29.6, 46.8))  # For SMR\n",
    "model.T_water = Var(bounds=(50, 80))  # For Water Electrolysis\n",
    "model.N_water = Var(bounds=(10, 50))  # For Water Electrolysis\n",
    "model.FH2O_dist = Var(bounds=(100, 200), initialize=150)  # For Distillation Column Separation, initialize with a value\n",
    "\n",
    "model.all_fAir = Var(bounds=(12000, 15000))  # For Cryogenic Nitrogen\n",
    "model.all_Plpc = Var(bounds=(0.01, 1.36))  # For Cryogenic Nitrogen\n",
    "model.P_membrane = Var(bounds=(5, 15))  # For Membrane Nitrogen\n",
    "model.Fair_membrane = Var(bounds=(2000, 2487.5))  # For Membrane Nitrogen\n",
    "\n",
    "model.FH2O_dist = Var(bounds=(100, 200))  # For Distillation Column Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "071236d6-6a85-4c6f-b95f-c2d29ca71f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraints for binary variables to ensure one option is selected per process section\n",
    "model.Hydrogen_constraint = Constraint(expr=model.SMR + model.WE == 1)\n",
    "model.Nitrogen_constraint = Constraint(expr=model.CAS + model.MAS == 1)\n",
    "model.Reactor_constraint = Constraint(expr=model.HB + model.MW == 1)\n",
    "model.Separation_constraint = Constraint(expr=model.Dist + model.Mem == 1)\n",
    "\n",
    "# A simple initial objective to maximize the sum of all decision variables (just to initialize)\n",
    "model.objective = Objective(expr=model.FNG + model.FH2O + model.Tsr + model.Psr + model.T_water + model.N_water +\n",
    "                                         model.all_fAir + model.all_Plpc + model.P_membrane + model.Fair_membrane + model.FH2O_dist,\n",
    "                                    sense=minimize)\n",
    "# Solver setup\n",
    "solver = SolverFactory('SCIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86cdc0c-45e1-4c01-ac92-07d387a7d845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "FNG: 80.0\n",
      "FH2O: 255.0\n",
      "Tsr: 900.0\n",
      "Psr: 29.6\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "SMR CAPEX: 1503950.25\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x30a00a8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x30a00a8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x30a0096c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x30a0096c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "CAS CAPEX: 264385.2\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "HB CAPEX: 34054.88671875\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Distillation CAPEX: 455038.8125\n",
      "Iteration 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/xfgqb3bx783_n7rkxqtvk2xc0000gn/T/ipykernel_15237/2402941364.py:181: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  total_expenses = float(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNG: 80.0\n",
      "FH2O: 255.0\n",
      "Tsr: 900.0\n",
      "Psr: 29.6\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "SMR CAPEX: 1503950.25\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "CAS CAPEX: 264385.2\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "HB CAPEX: 34054.88671875\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "Distillation CAPEX: 455038.8125\n",
      "Converged after 2 iterations.\n",
      "Optimized hydrogen production route: SMR\n",
      "Optimized nitrogen production route: Cryogenic\n",
      "Optimized reactor: Haber-Bosch\n",
      "Optimized separation: Distillation\n",
      "Optimal ammonia production (kmol/h): [69.91862]\n",
      "Total expenses in USD: 15764800.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Manual scaling function\n",
    "def scale_value(value, min_val, max_val):\n",
    "    return (value - min_val) / (max_val - min_val)\n",
    "\n",
    "# Iteration Loop to Optimize\n",
    "max_iterations = 50\n",
    "tolerance = 1e-4\n",
    "previous_objective = None\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    print(f\"Iteration {iteration+1}:\")\n",
    "\n",
    "    # Step 1: Solve the Pyomo model (initial run with a simple objective)\n",
    "    solver.solve(model)\n",
    "\n",
    "    # Step 2: Extract optimized decision variables\n",
    "    optimized_FNG = value(model.FNG)\n",
    "    print(f\"FNG: {optimized_FNG}\")\n",
    "    optimized_FH2O = value(model.FH2O)\n",
    "    print(f\"FH2O: {optimized_FH2O}\")\n",
    "    optimized_Tsr = value(model.Tsr)\n",
    "    print(f\"Tsr: {optimized_Tsr}\")\n",
    "    optimized_Psr = value(model.Psr)\n",
    "    print(f\"Psr: {optimized_Psr}\")\n",
    "    optimized_fAir = value(model.all_fAir)\n",
    "    optimized_Plpc = value(model.all_Plpc)\n",
    "    optimized_P_membrane = value(model.P_membrane)\n",
    "    optimized_Fair_membrane = value(model.Fair_membrane)\n",
    "    optimized_FH2O_dist = value(model.FH2O_dist)\n",
    "    optimized_T = value(model.T_water)\n",
    "    optimized_N = value(model.N_water)\n",
    "\n",
    "    # Initialize all variables\n",
    "    predicted_capex_hydrogen = 0\n",
    "    opex_raw_SMR = 0\n",
    "    predicted_opex_electricity_hydrogen = 0\n",
    "    predicted_hydrogen_flowrate = 0\n",
    "    opex_raw_WE = 0\n",
    "    predicted_capex_nitrogen = 0\n",
    "    predicted_opex_electricity_nitrogen = 0\n",
    "    predicted_nitrogen_flowrate = 0\n",
    "    ammonia_flowrate = 0\n",
    "    predicted_capex_HB = 0\n",
    "    predicted_opex_electricity_HB = 0\n",
    "    predicted_capex_MW = 0\n",
    "    predicted_opex_electricity_MW = 0\n",
    "    ammonia_production = 0\n",
    "    predicted_capex_dist = 0\n",
    "    predicted_opex_electricity_dist = 0\n",
    "    predicted_capex_mem = 0\n",
    "    predicted_opex_electricity_mem = 0\n",
    "    HB_cooling_water = 0\n",
    "    CAS_steam = 0\n",
    "    SMR_cooling_water_steam = 0\n",
    "    dist_cooling_water_steam_refrigerant = 0\n",
    "\n",
    "    # Use Keras models to get capex and opex predictions\n",
    "    if value(model.SMR) == 1:\n",
    "        # Scale values using manual scaling\n",
    "        scaled_FNG = scale_value(optimized_FNG, 80, 120)\n",
    "        scaled_FH2O = scale_value(optimized_FH2O, 255, 375)\n",
    "        scaled_Tsr = scale_value(optimized_Tsr, 900, 1100)\n",
    "        scaled_Psr = scale_value(optimized_Psr, 29.6, 46.8)\n",
    "        \n",
    "        # Create single input array\n",
    "        input_data = np.array([[scaled_FNG, scaled_FH2O, scaled_Tsr, scaled_Psr]])\n",
    "        predicted_capex_hydrogen = EA_SMR_Model.predict(input_data)[0][0]\n",
    "        \n",
    "        opex_raw_SMR = optimized_FNG * 24 * 330 * 890000 * 3.66 / 10**6\n",
    "        predicted_opex_electricity_hydrogen = SMR_ne_model.predict([[optimized_FNG, optimized_FH2O, optimized_Tsr, optimized_Psr]])[0] * 4.2 * 0.1638 * 24 * 3600 * 330/(3.6*10**6)\n",
    "        predicted_hydrogen_flowrate = SMR_fh2_model.predict([[optimized_FNG, optimized_FH2O, optimized_Tsr, optimized_Psr]])[0]\n",
    "        SMR_cooling_water_steam = 136 * 24 * 330 * 800.8/585.7\n",
    "        print(f\"SMR CAPEX: {predicted_capex_hydrogen}\")\n",
    "\n",
    "    elif value(model.WE) == 1:\n",
    "        predicted_capex_hydrogen = 26000000\n",
    "        predicted_opex_electricity_hydrogen = (WE_NE_model.predict([[value(model.T_water), value(model.N_water)]])[0]) * 10 * 0.1638 * 24 * 3600 * 330/(3.6*10**6)\n",
    "        predicted_hydrogen_flowrate = WE_H2_model.predict([[value(model.T_water), value(model.N_water)]])[0]\n",
    "        opex_raw_WE = predicted_hydrogen_flowrate * 24 * 330 * 410.75\n",
    "\n",
    "    # Similar predictions for nitrogen\n",
    "    if value(model.CAS) == 1:\n",
    "        # Scale values using manual scaling\n",
    "        scaled_fAir = scale_value(optimized_fAir, 12000, 15000)\n",
    "        scaled_Plpc = scale_value(optimized_Plpc, 0.01, 1.36)\n",
    "        \n",
    "        # Create single input array\n",
    "        input_data = np.array([[scaled_fAir, scaled_Plpc]])\n",
    "        predicted_capex_nitrogen = EA_CAS_Model.predict(input_data)[0][0] / 15\n",
    "        \n",
    "        predicted_opex_electricity_nitrogen = (CASU_ne_model.predict([[value(model.all_fAir), value(model.all_Plpc)]])[0]) * 0.1638 * 24 * 3600 * 330/(15*3.6*10**6)\n",
    "        predicted_nitrogen_flowrate = (fn2_fair_model.predict([[value(model.all_fAir), value(model.all_Plpc)]])[0])/15\n",
    "        CAS_steam = 445 * 24 * 330 * 800.8/585.7\n",
    "        print(f\"CAS CAPEX: {predicted_capex_nitrogen}\")\n",
    "\n",
    "    elif value(model.MAS) == 1:\n",
    "        # Scale values using manual scaling\n",
    "        scaled_P_membrane = scale_value(optimized_P_membrane, 5, 15)\n",
    "        scaled_Fair_membrane = scale_value(optimized_Fair_membrane, 2000, 2487.5)\n",
    "        \n",
    "        # Create single input array\n",
    "        input_data = np.array([[scaled_P_membrane, scaled_Fair_membrane]])\n",
    "        predicted_capex_nitrogen = EA_MAS_Model.predict(input_data)[0][0]\n",
    "        \n",
    "        predicted_opex_electricity_nitrogen = MASU_ne_model.predict([[value(model.P_membrane), value(model.Fair_membrane)]])[0] * 1000 * 0.1638 * 24 * 3600 * 330/(3.6*10**6)\n",
    "        predicted_nitrogen_flowrate = Fn2_P_model.predict([[value(model.P_membrane), value(model.Fair_membrane)]])[0]\n",
    "        print(f\"MAS CAPEX: {predicted_capex_nitrogen}\")\n",
    "\n",
    "    # Ammonia production from reactors\n",
    "    # Haber Bosch reactor\n",
    "    if value(model.HB) == 1:\n",
    "        ammonia_flowrate = Haber_f_model.predict(np.array([[predicted_nitrogen_flowrate[0], predicted_hydrogen_flowrate[0]]]))[0]\n",
    "        \n",
    "        # Scale values using manual scaling (adjust bounds as needed)\n",
    "        scaled_nitrogen = scale_value(predicted_nitrogen_flowrate[0], 0, 1000)\n",
    "        scaled_hydrogen = scale_value(predicted_hydrogen_flowrate[0], 0, 2000)\n",
    "        \n",
    "        # Create single input array\n",
    "        input_data = np.array([[scaled_nitrogen, scaled_hydrogen]])\n",
    "        predicted_capex_HB = EA_HB_Model.predict(input_data)[0][0]\n",
    "        \n",
    "        predicted_opex_electricity_HB = HB_ne_model.predict(np.array([[predicted_nitrogen_flowrate[0], predicted_hydrogen_flowrate[0]]]))[0][0] * 4.2 * 0.1638 * 24 * 3600 * 330/(3.6*10**6)\n",
    "        HB_cooling_water = 2 * 24 * 330 * 800.8/585.7\n",
    "        print(f\"HB CAPEX: {predicted_capex_HB}\")\n",
    "\n",
    "    elif value(model.MW) == 1:\n",
    "        # Microwave reactor\n",
    "        Vol_n2 = predicted_nitrogen_flowrate * (0.0821*593.15/(1.19*60*5.44))  # ml/h.gcat\n",
    "        volume_n2 = Vol_n2.reshape(-1,1)\n",
    "\n",
    "        vol_h2 = predicted_hydrogen_flowrate * (0.0821*593.15/(1.19*60*5.44))  # ml/h.gcat\n",
    "        \n",
    "        if isinstance(vol_h2, float):\n",
    "            vol_h2 = np.array([vol_h2])\n",
    "        volume_h2 = vol_h2.reshape(-1,1)\n",
    "\n",
    "        # Calculate the total inlet gas volume\n",
    "        F = volume_h2 + volume_n2\n",
    "\n",
    "        # Calculate the gas ratio\n",
    "        Ratio = volume_h2/volume_n2\n",
    "        Ratio = Ratio.reshape(-1,1)\n",
    "\n",
    "        ammonia_conc_MW = (my_model7.predict([[320, 80, Ratio[0][0], F[0][0]]])[0])/100\n",
    "\n",
    "        x_solution = ammonia_conc_MW*(predicted_nitrogen_flowrate+predicted_hydrogen_flowrate)/(2+2*ammonia_conc_MW)\n",
    "\n",
    "        molar_n2_mw = (predicted_nitrogen_flowrate - x_solution)*10\n",
    "        molar_h2_mw = (predicted_hydrogen_flowrate - 3*x_solution)*10\n",
    "        ammonia_flowrate = 2*x_solution*10\n",
    "\n",
    "        power_reactor = 340*212766\n",
    "        predicted_capex_MW = 212766*60000\n",
    "        predicted_opex_electricity_MW = 340 * 212766 * 0.1638 * 24 * 3600 * 330/(3.6*10**6)\n",
    "\n",
    "    # Separation\n",
    "    if value(model.Dist) == 1:\n",
    "        ammonia_production = dist_column_f_model.predict(np.array([[ammonia_flowrate[0], value(model.FH2O_dist)]]))[0]\n",
    "        \n",
    "        # Scale values using manual scaling (adjust bounds as needed)\n",
    "        scaled_ammonia = scale_value(ammonia_flowrate[0], 0, 500)\n",
    "        scaled_FH2O_dist = scale_value(value(model.FH2O_dist), 100, 200)\n",
    "        \n",
    "        # Create single input array\n",
    "        input_data = np.array([[scaled_ammonia, scaled_FH2O_dist]])\n",
    "        predicted_capex_dist = EA_Dist_Model.predict(input_data)[0][0]\n",
    "        \n",
    "        dist_cooling_water_steam_refrigerant = 184 * 24 * 330 * 800.8/585.7\n",
    "        predicted_opex_electricity_dist = dist_ne_model.predict(np.array([[ammonia_flowrate[0], value(model.FH2O_dist)]]))[0] * 4.2 * 0.1638 * 24 * 3600 * 330/(3.6*10**6)\n",
    "        print(f\"Distillation CAPEX: {predicted_capex_dist}\")\n",
    "        \n",
    "    elif value(model.Mem) == 1:\n",
    "        ammonia_production = 2.8e-8*100*0.3*10**6*ammonia_flowrate\n",
    "        predicted_capex_mem = 20000\n",
    "        predicted_opex_electricity_mem = 0\n",
    "\n",
    "    # Total expenses - make sure it's a scalar value\n",
    "    total_expenses = float(\n",
    "           HB_cooling_water + CAS_steam + SMR_cooling_water_steam + \n",
    "           predicted_capex_hydrogen + predicted_capex_nitrogen + \n",
    "           predicted_capex_HB + predicted_capex_MW + predicted_capex_dist + \n",
    "           predicted_capex_mem + predicted_opex_electricity_hydrogen + \n",
    "           predicted_opex_electricity_nitrogen + predicted_opex_electricity_HB + \n",
    "           predicted_opex_electricity_MW + predicted_opex_electricity_dist + \n",
    "           predicted_opex_electricity_mem + opex_raw_SMR + opex_raw_WE + \n",
    "           dist_cooling_water_steam_refrigerant)\n",
    "\n",
    "    # Update objective - convert to float for Pyomo\n",
    "    model.objective.expr = total_expenses\n",
    "\n",
    "    # Step 4: Check for convergence\n",
    "    current_objective = value(model.objective)\n",
    "    if previous_objective is not None and abs(current_objective - previous_objective) < tolerance:\n",
    "        print(f\"Converged after {iteration+1} iterations.\")\n",
    "        break\n",
    "\n",
    "    previous_objective = current_objective\n",
    "\n",
    "# Final optimized results\n",
    "print(\"Optimized hydrogen production route:\", \"SMR\" if value(model.SMR) == 1 else \"Water Electrolysis\")\n",
    "print(\"Optimized nitrogen production route:\", \"Cryogenic\" if value(model.CAS) == 1 else \"Membrane\")\n",
    "print(\"Optimized reactor:\", \"Haber-Bosch\" if value(model.HB) == 1 else \"Microwave\")\n",
    "print(\"Optimized separation:\", \"Distillation\" if value(model.Dist) == 1 else \"Membrane\")\n",
    "print(\"Optimal ammonia production (kmol/h):\", ammonia_production)\n",
    "print(\"Total expenses in USD:\", total_expenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a1897-2aad-4fc8-8b6e-1fa8fc94529c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f25caa-4fc7-4f16-bf0b-8203cf84342c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cb6d37-f6f0-495d-9e87-c88cce2e7d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a51181-75af-4945-8adc-390f3fe95f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff58d66-7abd-4b5c-86f2-a0bbd053030b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00deca73-ce93-476f-83b4-b3cedfc51ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8159ef1-d980-49d5-8830-cfd8aaa032e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fe5da-2c0d-4bcc-b545-1e64af7bb5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d146ae-084c-429f-a13d-a990318af5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c3649-53fb-46f2-8864-11e155cfe81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14577d3b-2cd3-4256-bdee-22d1284beef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12226c09-470c-4381-aab0-096f14cae463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d91ad-c181-4ecd-b20f-29a8eda90760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f197b-16b4-4c27-bb8e-bc105dae2a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e24485-3f91-48ce-a230-2a0c006d15fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f14a2-42fe-4794-9025-d431ced45caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
